{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test technique pour le stage data science chez Bouygues Telecom\n",
    "\n",
    "<div style=\"text-align: right;\"><span style=\"font-style: italic; margin-right: 1.5em;\">Gabriel Watkinson</span></div> \n",
    "<hr class=\"solid\">\n",
    "\n",
    "Ce notebook contient le test technique pour le stage de data science chez Bouygues Telecom basée sur des données factices sur la résiliation des clients ayant un abonnement télécom.\n",
    "\n",
    "### Description du test\n",
    "\n",
    "L'objectif est de comprendre et de prédire la résilation des clients. Pour ce faire 4 datasets sont fournis :\n",
    "\n",
    "* resiliation_option : contient les données sur les options des forfaits fixe et mobile des clients\n",
    "* resiliation_client : contient des données clients\n",
    "* resiliation_contrat : contient les caractéristiques des contrats des clients\n",
    "* resiliation_forfait : contient les caractéristiques du forfait mobile du client\n",
    "\n",
    "### Organisation du notebook\n",
    "\n",
    "Le notebook est composé de 3 parties et d'une conclusion :\n",
    "\n",
    "1. Analyses des données et statistiques descriptives\n",
    "2. Préparation de données\n",
    "3. Modélisation du problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses des données et statistiques descriptives\n",
    "\n",
    "Dans un premier temps, nous analyserons les données pour comprendre leur contenu et leur structure en utilisant des statistiques descriptives et des graphiques pour visualiser les distributions des données, ainsi que les problèmes éventuels, comme les données manquantes par exemple, qui devront être pris en compte lors de la modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA automatique avec `pandas_profiling`\n",
    "\n",
    "Pour ce faire, nous allons utiliser `pandas_profiling` qui permet d'explorer les données et de soulever certain problèmes de manière automatique. Puis nous allons regarder manuellement certaines corrélations. Cela va créer des profils avec des informations sur chaques variables (moyenne, médiane, valeurs manquantes, etc.), mais aussi sur quelques intéractions entre les variables (corrélations, etc.).\n",
    "\n",
    "Ces profils sont ensuite exportés en format html dans le dossier nommé `profiles`.\n",
    "\n",
    "Les données sont chargées à partir du dossier `data` qui se situe dans la racine du projet (comme ce notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement des données situées dans le dossier `data/`\n",
    "data_folder = \"./data/\"\n",
    "client = pd.read_csv(data_folder + \"resiliation_client.csv\", sep=\";\")\n",
    "contrat = pd.read_csv(data_folder + \"resiliation_contrat.csv\", sep=\";\")\n",
    "forfait = pd.read_csv(data_folder + \"resiliation_forfait.csv\", sep=\";\")\n",
    "option = pd.read_csv(data_folder + \"resiliation_option.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# Création des profils automatiques\n",
    "# Création du dossier `profils` qui contient les profils en html\n",
    "os.makedirs(\"profils\", exist_ok=True)\n",
    "\n",
    "print(\"Pour la table client :\")\n",
    "profil_client = ProfileReport(client, title=\"Profil de la table client\")\n",
    "profil_client.to_file(\"profils/profil_client.html\")\n",
    "\n",
    "print(\"Pour la table contrat :\")\n",
    "profil_contrat = ProfileReport(contrat, title=\"Profil de la table contrat\")\n",
    "profil_contrat.to_file(\"profils/profil_contrat.html\")\n",
    "\n",
    "print(\"Pour la table option :\")\n",
    "profil_option = ProfileReport(option, title=\"Profil de la table option\")\n",
    "profil_option.to_file(\"profils/profil_option.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profil `resiliation_client`\n",
    "\n",
    "Nous commençons avec la table qui contient les données clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profil_client.to_notebook_iframe()  # Affiche le profil dans une iframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table `resiliation_client` contient des données personnelles sur les clients, à savoir leur genre, leur situation familliale (en couple, parent) et une indication sur leur âge. Il y a également une information sur leur ancienneté chez Bouygues Telecom (en mois je suppose).\n",
    "\n",
    "Le profil donne un certain nombre d'informations interessantes :\n",
    "\n",
    "* Il y a un total de 7043 observations et 7043 identifiants de clients différents. L'id_client est donc une clé primaire qui peut être utilisée pour joindre les tables.\n",
    "* L'ancienneté a une distribution assez particulière :\n",
    "  * Avec une forte concentration sur les clients avec une très faible ancienneté, avec 1062 des clients qui ont moins de 3 mois d'ancienneté, soit 15% du nombre total. On note que l'ancienneté diminue assez vite les premiers mois avant de se stabiliser.\n",
    "  * Mais aussi sur les clients très anciens, avec 362 clients qui ont 72 mois d'ancienneté, soit 9% des clients. Il faut noter que 72 mois est le maximum recensé dans le dataset. On peut supposer que 72 correspond aux clients qui ont plus de 72 mois d'ancienneté. Cependant, on voit tout de même que 71 et 70 sont des valeurs très fréquentes. Il y a peut être une autre raison.\n",
    "  * Finalement, on peut noter des pics tous les 2 à 3 mois. Il pourrait être important de s'y intéresser, pour savoir si c'est notamment dû à des campagnes de marketing ou à des changements de tarifs par exemple.\n",
    "* Il y a un total de 4305 observations manquantes soit 10.2% des données. Ces données manquantes sont réparties entre le genre des clients (où 10% des données sont manquantes) et leur situation parentale (où 51% des données sont manquantes). On peut voir que l'absence de la situation parentale n'implique pas l'absence du genre, et inversement. Les absences de ces variables ne sont pas corrélées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, il peut être intéressant de noter la forte corrélation entre le fait d'être en couple et la situation parentale. En effet, le graphique suivant montre que, parmi les clients en couple, la moitié sont parents, alors que parmi les clients qui ne sont pas en couple, la grosse majorité n'est pas parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "ax = sns.countplot(data=client.fillna({\"parent\": \"NaN\"}), x=\"couple\", hue=\"parent\")\n",
    "ax.set(\n",
    "    xlabel=\"Couple\",\n",
    "    ylabel=\"Nombre de clients\",\n",
    "    title=\"Relation entre être en couple et être parent\",\n",
    ")\n",
    "ax.legend(title=\"Parent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, on voit clairement que les clients les plus anciens sont plus souvent en couple que les nouveaux clients. On peut donc penser que les clients célibataires sont plus enclins à résilier leur abonnement alors que les clients en couples le font moins souvent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(data=client, x=\"anciennete\", hue=\"couple\", cut=0, multiple=\"fill\")\n",
    "ax.set(\n",
    "    xlabel=\"Ancienneté\",\n",
    "    ylabel=\"Pourcentage des clients\",\n",
    "    title=\"Proportion des clients en couple selon l'ancienneté\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profil `resiliation_forfait`\n",
    "\n",
    "Pour la table avec les informations sur les forfaits, il n'est pas nécessaire de faire un profil. On peut simplement regarder les données car il n'y a que quelques lignes.\n",
    "\n",
    "En effet, cette table contient uniquement la quantité de Go par mois pour les différents forfaits mobile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forfait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profil `resiliation_contrat`\n",
    "\n",
    "Regardons ensuite la table `resiliation_contrat` qui contient les informations sur les contrats des clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profil_contrat.to_notebook_iframe()  # Affiche le profil dans une iframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table `resiliation_contrat` contient les données sur les contrats souscrits par les clients, à savoir le forfait, la durée du contrat (mensuel, annuel, biannuel), la méthode de paiement, la facture mensuelle moyenne, la facture totale et surtout si le client a résilé son abonnement ou non. \n",
    "\n",
    "Le profil donne un certain nombre d'informations interessantes :\n",
    "\n",
    "* Comme dans la table sur les clients, l'id_client est une clé primaire. On vérifiera dans la suite que ce sont bien les mêmes clients qui sont présents dans les deux tables.\n",
    "* On peut voir qu'il y a seulement 4 types de forfaits dans cette table, alors que la table sur les forfait en contient 5. Il y en a donc un qui n'est pas utilisé.\n",
    "* Il y a moins d'observations manquantes que dans la table sur les clients, avec 9.7% des forfaits manquants.\n",
    "* Il est très important de remarquer que le nombre d'observations avec résiliation est beaucoup plus faible que celui sans résiliation. Les classes de la *target* ne sont donc pas équilibrées. Il faudra donc y faire attention en choisissant une métrique de classification pertinente ou en appliquant des méthodes de *sampling*.\n",
    "\n",
    "Maintenant, regardons quelques interactions entre les variables. Nous d'abord ajouter l'ancienneté au dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rajoute l'ancienneté à la table des contrats pour observer des corrélations\n",
    "tmp1 = pd.merge(\n",
    "    client[[\"id_client\", \"anciennete\"]],\n",
    "    contrat[\n",
    "        [\n",
    "            \"id_client\",\n",
    "            \"id_forfait\",\n",
    "            \"facture_mensuelle_moyenne\",\n",
    "            \"contrat\",\n",
    "            \"resiliation\",\n",
    "        ]\n",
    "    ],\n",
    "    on=\"id_client\",\n",
    ")\n",
    "tmp1 = pd.merge(tmp1, forfait, on=\"id_forfait\", how=\"left\")\n",
    "tmp1.head()  # Table provisoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(30, 5))\n",
    "sns.kdeplot(\n",
    "    data=tmp1, x=\"anciennete\", hue=\"resiliation\", multiple=\"stack\", ax=ax1, cut=0\n",
    ")\n",
    "ax1.set(\n",
    "    xlabel=\"Ancienneté\",\n",
    "    ylabel=\"Pourcentage des clients qui résilient\",\n",
    "    title=\"Résiliation selon l'ancienneté\",\n",
    ")\n",
    "sns.boxplot(\n",
    "    data=tmp1.fillna({\"go_forfait\": \"NaN\"}),\n",
    "    x=\"go_forfait\",\n",
    "    y=\"facture_mensuelle_moyenne\",\n",
    "    ax=ax2,\n",
    "    hue=\"resiliation\",\n",
    ")\n",
    "ax2.set(\n",
    "    xlabel=\"Forfait\",\n",
    "    ylabel=\"Facture mensuelle moyenne\",\n",
    "    title=\"Facture mensuelle moyenne par forfait\",\n",
    ")\n",
    "sns.countplot(data=tmp1, x=\"contrat\", hue=\"resiliation\", ax=ax3)\n",
    "ax3.set(\n",
    "    xlabel=\"Durée du contrat\",\n",
    "    ylabel=\"Nombre de clients\",\n",
    "    title=\"Résiliation selon la durée du contrat\",\n",
    ")\n",
    "sns.countplot(\n",
    "    data=tmp1.fillna({\"go_forfait\": \"NaN\"}),\n",
    "    x=\"go_forfait\",\n",
    "    hue=\"resiliation\",\n",
    "    ax=ax4,\n",
    ")\n",
    "ax4.set(\n",
    "    xlabel=\"Forfait\",\n",
    "    ylabel=\"Nombre de clients qui résilient\",\n",
    "    title=\"Nombre de clients qui résilient selon le forfait\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le graphique de gauche, on voit que l'ancienneté des clients a un effet très important sur la résiliation, en effet, les clients anciens ont moins tendance à résilier leur abonnement que les nouveaux clients. \n",
    "\n",
    "Dans un deuxième temps, le graphique de droite montre que, quelque soit le forfait, les clients qui ont résilier avaient une facture mensuelle plus faible que les clients qui n'ont pas résilier. Cela peut être dû à des promotions à durée fixe, et donc, une fois cette durée terminée, les clients ont tendance à résilier leur abonnement. Ce qui est en accordance avec le premier graphique.\n",
    "\n",
    "Ensuite, on peut voir que les données avec le forfait manquant sont très différents des autres en terme de facture mensuelle. En effet, les factures se situent entre le forfait à 20Go et celui à 80Go. On note clairement que la facture mensuelle est très corrélée à la quantité de Go. On peut donc supposer que les forfait manquants correspondent à celui qui n'est pas utilisé et qui contient 50Go. Cette hypothèse sera retenue lors du traitement des valeurs manquantes.\n",
    "\n",
    "Sur le graphique suivant, on voit que les longs contrats sont moins susceptibles d'être résilier que les contrats courts.\n",
    "\n",
    "Finalement, le dernier graphique montre que les gros abonnements à 200Go sont plus susceptibles de résilier que les autres abonnements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profil `resiliation_option`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profil_option.to_notebook_iframe()  # Affiche le profil dans une iframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La table `resiliation_option` contient les données sur les options ajoutées aux forfaits par les clients, notamment des options de téléphonie, de télévision, de sécurité, de support ou de stream.\n",
    "\n",
    "Les seules valeurs manquantes sont dans les options de streaming, qui sont corrélées, en effet, si une des options est manquantes, l'autre l'ait également.\n",
    "\n",
    "On remarque que toutes les options sont très corrélées avec la variable `service_internet`. En effet, si le service internet n'est pas inclu dans le forfait, aucune options ne peut l'être.\n",
    "Cependant, ce ne sont pas des variables redondantes, car il y a tout de même des options choisies par certains clients.\n",
    "\n",
    "On peut faire la même remarque pour l'option téléphonie et les lignes multiples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(25, 5), sharey=True)\n",
    "sns.countplot(data=option, x=\"service_internet\", hue=\"option_securite\", ax=axs[0])\n",
    "axs[0].set(\n",
    "    xlabel=\"Service internet\",\n",
    "    ylabel=\"Nombre de clients\",\n",
    "    title=\"Service internet selon l'option de sécurité\",\n",
    ")\n",
    "sns.countplot(data=option, x=\"service_internet\", hue=\"stream_TV\", ax=axs[1])\n",
    "axs[1].set(\n",
    "    xlabel=\"Service internet\",\n",
    "    ylabel=\"Nombre de clients\",\n",
    "    title=\"Service internet selon l'option de stream TV\",\n",
    ")\n",
    "sns.countplot(data=option, x=\"service_internet\", hue=\"protection_terminal\", ax=axs[2])\n",
    "axs[2].set(\n",
    "    xlabel=\"Service internet\",\n",
    "    ylabel=\"Nombre de clients\",\n",
    "    title=\"Service internet selon l'option protection terminal\",\n",
    ")\n",
    "sns.countplot(\n",
    "    data=option, x=\"option_service_telephone\", hue=\"multiple_ligne\", ax=axs[3]\n",
    ")\n",
    "axs[3].set(\n",
    "    xlabel=\"Option service téléphonique\",\n",
    "    ylabel=\"Nombre de clients\",\n",
    "    title=\"Option service téléphonique selon l'option de multiple ligne\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le graphique suivant, on constate encore que les clients avec un forfait manquant sont uniques, en effet, aucun n'ont l'option de service telephonique.\n",
    "Cela renforce l'idée que les forfaits manquants sont dans une catégorie distincte, plutôt que des valeurs manquantes réparties entre les différents forfaits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = pd.merge(\n",
    "    contrat[[\"id_client\", \"id_forfait\", \"facture_mensuelle_moyenne\"]],\n",
    "    option,\n",
    "    on=\"id_client\",\n",
    ")\n",
    "ax = sns.countplot(\n",
    "    data=tmp2.fillna({\"id_forfait\": \"NaN\"}),\n",
    "    x=\"id_forfait\",\n",
    "    hue=\"option_service_telephone\",\n",
    ")\n",
    "ax.set(\n",
    "    xlabel=\"Forfait\",\n",
    "    ylabel=\"Nombre de clients\",\n",
    "    title=\"Nombre de clients par forfait en fonction de l'option de service\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation de données\n",
    "\n",
    "Dans cette partie, nous allons travailler les données et les préparer pour qu'elles puissent être utilisées dans nos modèles.\n",
    "\n",
    "Nous allons donc traiter le cas des valeurs manquantes et de la transformation des variables catégorielles en variables numériques.\n",
    "\n",
    "Commençons par regrouper les données dans un dataframe nommé `df` en vérifiant que les id_client sont bien identiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    contrat,\n",
    "    client,\n",
    "    on=\"id_client\",\n",
    "    how=\"outer\",\n",
    "    validate=\"1:1\",\n",
    "    indicator=\"client_contrat\",\n",
    ")\n",
    "df = pd.merge(\n",
    "    df, option, on=\"id_client\", how=\"outer\", validate=\"1:1\", indicator=\"client_option\"\n",
    ")\n",
    "df = pd.merge(\n",
    "    df, forfait, on=\"id_forfait\", how=\"left\", validate=\"m:1\", indicator=\"client_forfait\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"client_contrat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"client_option\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"client_forfait\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate donc bien que les id_client sont des clés primaires et que les jointures sont bien en *one to one*.\n",
    "\n",
    "Pour les forfaits, comme mentionné précedemment, on voit qu'il y en a qui sont manquants et qu'un forfait n'est pas du tout présent.\n",
    "\n",
    "Générons le profil général, qui peut être interressant pour les corrélations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profil_total = ProfileReport(df, title=\"Profil de la dataframe finale\")\n",
    "profil_total.to_file(\"profils/profil_total.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des variables\n",
    "\n",
    "Pour commencer, nous allons évoquer les méthodes possibles pour traiter les différentes varibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons donc regarder variables par variables ce qu'il est necéssaire de faire :\n",
    "\n",
    "* Tout d'abord, l'`id_client` est une clé primaire, donc elle ne contient pas d'information et il faut donc l'utiliser comme index.\n",
    "* Les variables `client_contrat`, `client_option` et `client_forfait` ont été créées pour vérifier les clées primaires. Il faut donc les supprimer.\n",
    "* L'`id_forfait` n'apporte pas plus d'information que la quantité de Go, mais on peut tout de même la garder pour les encoder. De plus, d'après les hypothèses précedentes, on peut supposer que le forfait manquant est celui qui n'est pas utilisé, et donc, mettre la valeur de 50Go.\n",
    "* La variable `contrat` apporte une information sur la durée du contrat, il semble donc que c'est une variable numérique. On la convertit donc en nombre de mois, quitte à la considérer comme une variable catégorielles par la suite.\n",
    "* La variable `facture_totale` a quelques valeurs manquantes, on peut les remplir en supposant que la facture totale vaut l'ancienneté fois le facture mensuelle moyenne. Cependant, la facture totale est manquante que quand l'ancienneté vaut 0. On peut donc remplacer par 0.\n",
    "* Les variables `facture_digitale`, `senior`, `couple`, `parent`, et `option_service_telephone` sont des booléens, on peut donc les convertir en variables numériques avec 0 pour Non et 1 pour Oui.\n",
    "* Les autres variables ne peuvent pas être converties aussi facilement, effectivement, ce sont des variables catégorielles avec plusieurs valeurs possibles. On peut donc utiliser plusieurs méthodes pour les transformer.\n",
    "  * On peut notamment utiliser du OneHotEncoding, ce qui est assez simple mais risque de rajouter un nombre important de colonnes redondantes (Pas de service internet notamment).\n",
    "  * On peut utiliser des Encoders plus complexes, comme ceux de `category_encoders`, tel que `TargetEncoder` qui encode une catégorie en la moyenne de la variable *target*, ce qui *\"équivaut à la probabilité\"* de résiliation pour la catégorie. Ces estimateurs peuvent ensuite être utilisés sur les données de test en imputant les valeures apprises sur les données d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va tout d'abord séparer les données en deux groupes : les données d'entrainement et les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataframe finale\n",
    "final_df = df.set_index(\"id_client\").drop(\n",
    "    [\"client_contrat\", \"client_option\", \"client_forfait\"], axis=1\n",
    ")\n",
    "# Split data et target\n",
    "X, y = final_df.drop(\"resiliation\", axis=1), final_df[\"resiliation\"]\n",
    "# Split data en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Sauvegarde les données générées et csv\n",
    "os.makedirs(\"./data/train\", exist_ok=True)\n",
    "os.makedirs(\"./data/test\", exist_ok=True)\n",
    "X_train.to_csv(\"./data/train/X_train.csv\")\n",
    "y_train.to_csv(\"./data/train/y_train.csv\")\n",
    "X_test.to_csv(\"./data/test/X_test.csv\")\n",
    "y_test.to_csv(\"data/test/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous allons utiliser `sklearn-pandas` pour associer un ou plusieurs estimateurs pour chaque variable catégorielles, afin de les transformer en features utilisable par nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing(df):\n",
    "#     \"\"\"Cette fonction permet de pré-traiter les données.\n",
    "\n",
    "#     Args:\n",
    "#         data (DataFrame): La dataframe à pré-traiter sans la colonne target\n",
    "#             et avec les id_client en indice. Cette fonction doit fonctionner\n",
    "#             à la fois sur les données d'entrainement et de test.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: La dataframe pré-traitée.\n",
    "#     \"\"\"\n",
    "#     # On copie la dataframe pour ne pas la modifier\n",
    "#     data = df.copy()\n",
    "#     data = data.drop(\"id_forfait\", axis=1)  # On enlève la colonne id_forfait\n",
    "#     # On remplace les valeurs booléennes et numériques par des entiers\n",
    "#     data = data.replace(\n",
    "#         {\n",
    "#             \"contrat\": {\"Mensuel\": 1, \"un an\": 12, \"deux ans\": 24},\n",
    "#             # \"facture_digitale\": {\"Oui\": 1, \"Non\": 0},\n",
    "#             # \"senior\": {\"Oui\": 1, \"Non\": 0},\n",
    "#             # \"couple\": {\"Oui\": 1, \"Non\": 0},\n",
    "#             # \"parent\": {\"Oui\": 1, \"Non\": 0},\n",
    "#             # \"option_service_telephone\": {\"Oui\": 1, \"Non\": 0},\n",
    "#         }\n",
    "#     )\n",
    "#     # On remplace les valeurs manquantes dans les Go par 50.\n",
    "#     data = data.fillna({\"go_forfait\": 50})\n",
    "#     # On remplace les valeurs manquantes dans les factures totales par 0.\n",
    "#     data = data.fillna({\"facture_totale\": 0})\n",
    "#     return data\n",
    "#\n",
    "#\n",
    "# def final_processing(df, mapper):\n",
    "#     \"\"\"Cette fonction est un wrapper pour les fonctions de preprocessing.\n",
    "\n",
    "#     Elle applique le mapper et supprime les colonnes redondantes issues du OneHotEncoding.\n",
    "\n",
    "#     Args:\n",
    "#         data (DataFrame): La dataframe à finalement transformer.\n",
    "#         mapper (DataFrameMapper): Le mapper fitter auparavant qui a été utilisé pour transformer les données.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: La dataframe finalement transformée.\n",
    "#     \"\"\"\n",
    "#     # On copie la dataframe pour ne pas modifier la dataframe d'origine\n",
    "#     data = df.copy()\n",
    "#     # On applique le premier processing\n",
    "#     # data = preprocessing(data)\n",
    "#     # On transforme les données avec le mapper\n",
    "#     data = mapper.transform(data)\n",
    "#     # On supprime les colonnes redondantes\n",
    "#     data = data.drop(data.filter(regex=\"Pas de service internet\").columns, axis=1)\n",
    "#     data = data.drop(data.filter(regex=\"Pas de ligne telephonique\").columns, axis=1)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    LabelEncoder,\n",
    "    MinMaxScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "# Mapper qui permet de transformer les colonnes en colonnes numériques\n",
    "# La stratégie de transformation est la plus simple pour le moment, pour les données manquantes,\n",
    "# on impute avec la valeur la plus fréquente. Pour les données categoriales, on utilise du OneHotEncoding.\n",
    "# Pour les données numériques, on utilise des transformations standards (StandardScaler, PowerTransformer, MinMaxScaler).\n",
    "mapper = DataFrameMapper(\n",
    "    [\n",
    "        (\n",
    "            [\"id_forfait\"],\n",
    "            [\n",
    "                SimpleImputer(strategy=\"constant\", fill_value=\"Dktt\"),\n",
    "                OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "            ],\n",
    "        ),\n",
    "        ([\"go_forfait\"], SimpleImputer(strategy=\"constant\", fill_value=50)),\n",
    "        ([\"contrat\"], OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ([\"facture_digitale\"], OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "        ([\"methode_paiement\"], OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ([\"facture_mensuelle_moyenne\"], MinMaxScaler()),\n",
    "        (\n",
    "            [\"facture_totale\"],\n",
    "            [SimpleImputer(strategy=\"constant\", fill_value=0), PowerTransformer()],\n",
    "        ),\n",
    "        (\n",
    "            [\"genre\"],\n",
    "            [\n",
    "                SimpleImputer(strategy=\"most_frequent\"),\n",
    "                OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "            ],\n",
    "        ),\n",
    "        ([\"senior\"], OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ([\"couple\"], OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        (\n",
    "            [\"parent\"],\n",
    "            [\n",
    "                SimpleImputer(strategy=\"most_frequent\"),\n",
    "                OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"),\n",
    "            ],\n",
    "        ),\n",
    "        ([\"anciennete\"], MinMaxScaler()),\n",
    "        ([\"option_service_telephone\"], OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ([\"multiple_ligne\"], OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "        ([\"service_internet\"], OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ([\"option_securite\"], OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "        ([\"option_backup\"], OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "        ([\"protection_terminal\"], OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "        ([\"support_technique\"], OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\")),\n",
    "        (\n",
    "            [\"stream_TV\"],\n",
    "            [\n",
    "                SimpleImputer(strategy=\"most_frequent\"),\n",
    "                OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"),\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            [\"stream_Films\"],\n",
    "            [\n",
    "                SimpleImputer(strategy=\"most_frequent\"),\n",
    "                OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    df_out=True,\n",
    ")\n",
    "\n",
    "# On ajoute un column transformer pour supprimer les colonnes redondantes\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"drop_internet\",\n",
    "            \"drop\",\n",
    "            make_column_selector(pattern=\"Pas de service internet\"),\n",
    "        ),\n",
    "        (\n",
    "            \"drop_telephonique\",\n",
    "            \"drop\",\n",
    "            make_column_selector(pattern=\"Pas de ligne telephonique\"),\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "mapper1 = make_pipeline(mapper, ct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, si on applique ce mapper au dataset `X_train`, on obtient :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    mapper1.fit_transform(X_train),\n",
    "    columns=ct.get_feature_names_out(),\n",
    "    index=X_train.index,\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de faire un autre mapper afin d'avoir un autre encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce mapper utilise du target encoding, il faut donc fit avec la target. De plus, TargetEncoder renvoie la moyenne s'il y a des données manquantes.\n",
    "mapper2 = DataFrameMapper(\n",
    "    [\n",
    "        (\n",
    "            [\"id_forfait\"],\n",
    "            [SimpleImputer(strategy=\"constant\", fill_value=\"Dktt\"), TargetEncoder()],\n",
    "        ),\n",
    "        ([\"go_forfait\"], SimpleImputer(strategy=\"constant\", fill_value=50)),\n",
    "        ([\"contrat\"], TargetEncoder()),\n",
    "        ([\"facture_digitale\"], TargetEncoder()),\n",
    "        ([\"methode_paiement\"], TargetEncoder()),\n",
    "        ([\"facture_mensuelle_moyenne\"], None),\n",
    "        ([\"facture_totale\"], SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        ([\"genre\"], TargetEncoder()),\n",
    "        ([\"senior\"], TargetEncoder()),\n",
    "        ([\"couple\"], TargetEncoder()),\n",
    "        ([\"parent\"], TargetEncoder()),\n",
    "        ([\"anciennete\"], None),\n",
    "        ([\"option_service_telephone\"], TargetEncoder()),\n",
    "        ([\"multiple_ligne\"], TargetEncoder()),\n",
    "        ([\"service_internet\"], TargetEncoder()),\n",
    "        ([\"option_securite\"], TargetEncoder()),\n",
    "        ([\"option_backup\"], TargetEncoder()),\n",
    "        ([\"protection_terminal\"], TargetEncoder()),\n",
    "        ([\"support_technique\"], TargetEncoder()),\n",
    "        ([\"stream_TV\"], TargetEncoder()),\n",
    "        ([\"stream_Films\"], TargetEncoder()),\n",
    "    ],\n",
    "    df_out=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce mapper renvoie une dataframe très différente, en effet, les colonnes ne sont pas dupliquées pour faire du OneHotEncoding, de plus la stratégie pour les valeurs manquantes est différente. Elle sont remplacées par la valeurs moyenne de la variable target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper2.fit_transform(X_train, LabelEncoder().fit_transform(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation\n",
    "\n",
    "Nous allons maintenant passer à la modélisation. Dans un premier temps, nous mettrons en place un modèle de base (régression logistique) pour avoir un premier score.\n",
    "\n",
    "La métrique utilisée sera le **recall**. En effet, le recall semble important car il décrit le nombre de clients qui résilient, et qui n'ont pas été prédit comme tel par le modèle. Cela est donc utile si l'objectif est de conserver les clients le plus possible.\n",
    "\n",
    "Par exemple, si on veut prévoir des clients à integrer dans une campagne de démarchage, ce modèle fournira la majorité des clients qui sont très suceptibles de résilier, en plus d'une quantité non négligeable de clients qui n'avait pas l'intention de résilier. Mais cela permet quand même de réduire drastiquement le scope de l'opération de démarchage.\n",
    "\n",
    "Mais, il reste important de regarder la précision pour ne pas tout prédire comme résilient. Pour cela, on peut regarder le **f1 score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fit sur les données de train. Il est également possible de les rajouter dans des pipelines.\n",
    "le = LabelEncoder().fit(y_train)\n",
    "mapper1.fit(X_train, le.transform(y_train))\n",
    "mapper2.fit(X_train, le.transform(y_train))\n",
    "# X_train_processed = mapper1.transform(X_train)\n",
    "# X_test_processed = mapper1.transform(X_test)\n",
    "# y_train_processed = le.transform(y_train)\n",
    "# y_test_processed = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "\n",
    "# Fonctions pour afficher la matrice de confusion\n",
    "def plot_confusion_matrix(y_true, y_pred, label_encoder):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        display_labels=label_encoder.classes_,\n",
    "        ax=ax1,\n",
    "        cmap=\"Blues\",\n",
    "        normalize=\"true\",\n",
    "        values_format=\".0%\",\n",
    "    )\n",
    "    ax1.grid(False)\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true, y_pred, display_labels=label_encoder.classes_, ax=ax2, cmap=\"Blues\"\n",
    "    )\n",
    "    ax2.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Fonction pour afficher la matrice de confusion ainsi que certains scores\n",
    "def plot_results(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    label_encoder,\n",
    "    metrics=[f1_score, roc_auc_score, precision_score, recall_score],\n",
    "):\n",
    "    for metric in metrics:\n",
    "        print(metric.__name__, metric(y_true, y_pred))\n",
    "    plot_confusion_matrix(y_true, y_pred, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui entraine un modèle après appliquer un mapper et renvoie les scores et la matrice de confusion\n",
    "def test_model(model, mapper, X_train, y_train, X_test, y_test, label_encoder):\n",
    "    pipe = make_pipeline(mapper, model)\n",
    "    pipe.fit(X_train, label_encoder.transform(y_train))\n",
    "    y_true, y_pred = label_encoder.transform(y_test), pipe.predict(X_test)\n",
    "    plot_results(y_true, y_pred, label_encoder)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "# Ajoute le sampling\n",
    "def test_model_with_sampling(\n",
    "    model, mapper, sampler, X_train, y_train, X_test, y_test, label_encoder\n",
    "):\n",
    "    y_train_processed = label_encoder.transform(y_train)\n",
    "    X_train_processed = mapper.fit_transform(X_train, y_train_processed)\n",
    "    X_test_processed = mapper.transform(X_test)\n",
    "    X_res, y_res = sampler.fit_resample(X_train_processed, y_train_processed)\n",
    "    clf = model.fit(X_res, y_res)\n",
    "    y_true, y_pred = label_encoder.transform(y_test), clf.predict(X_test_processed)\n",
    "    plot_results(y_true, y_pred, label_encoder)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de base\n",
    "\n",
    "Premièrement, nous allons utiliser un modèle de base, afin d'avoir une idée de la performance d'un modèle simple, en l'occurence, un modèle de régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "print(\"Pour le mapper 1\")\n",
    "log_reg_1 = test_model(clf, mapper1, X_train, y_train, X_test, y_test, le)\n",
    "print(\"Pour le mapper 2\")\n",
    "log_reg_2 = test_model(clf, mapper2, X_train, y_train, X_test, y_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit donc que les deux preprocessing des données donnent des résultats similaires pour une regression logistique (le mapper 1 fonctionne un tout petit peu mieux que le mapper 2).\n",
    "\n",
    "Le score f1 est à 0.63, ce qui est assez moyen, et surtout, le recall est très faible. Sur les 373 clients qui ont résilié dans le test set, il y a seulement 217 clients qui ont été prédit comme tel. Ce qui fait que l'on perdrait beacoup de clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "print(\"Pour le mapper 1\")\n",
    "rf_1 = test_model(clf, mapper1, X_train, y_train, X_test, y_test, le)\n",
    "print(\"Pour le mapper 2\")\n",
    "rf_2 = test_model(clf, mapper2, X_train, y_train, X_test, y_test, le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce problème est encore pire si on regarde un RandomForest classique.\n",
    "\n",
    "Il faut donc essayer de gérer le problème de déséquilibre des classes. Pour cela, on peut utiliser des technique de sampling qui enlève des données de la classes dominantes de manière aléatoire, ou rajoute des observations.\n",
    "Pour ce faire, on va utiliser le package `imblearn` qui contient des stratégies de sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, BorderlineSMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "smoteen = SMOTEENN(random_state=42)\n",
    "tomek = TomekLinks()\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "print(\"Pour le mapper 1 avec SMOTE\")\n",
    "lr_smote = test_model_with_sampling(\n",
    "    clf, mapper1, smote, X_train, y_train, X_test, y_test, le\n",
    ")\n",
    "print(\"Pour le mapper 1 avec SMOTEEN\")\n",
    "lr_smoteen = test_model_with_sampling(\n",
    "    clf, mapper1, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")\n",
    "print(\"Pour le mapper 1 avec TomekLinks\")\n",
    "lr_smoteen = test_model_with_sampling(\n",
    "    clf, mapper1, tomek, X_train, y_train, X_test, y_test, le\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit clairement, que cette technique permet d'améliorer de manière significative le recall, qui passe d'environ 50% à presque 90% avec le sampler SMOTEEN. Cepandant, la précision diminue significativement et le score f1 reste autour de 0.6.\n",
    "\n",
    "Dans la suite, nous allons utiliser le sampler SMOTEEN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essai de XGBoost, LightGBM, réseaux de neurones ...\n",
    "\n",
    "Ici, nous allons de tester différents modèles de classification, pour voir s'il est possible d'améliorer le modèle de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(random_state=42)\n",
    "print(\"Essai avec XGBClassifier et SMOOTEEN pour le mapper 1\")\n",
    "xgb_1 = test_model_with_sampling(\n",
    "    clf, mapper1, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")\n",
    "print(\"Essai avec XGBClassifier et SMOOTEEN pour le mapper 2\")\n",
    "xgb_2 = test_model_with_sampling(\n",
    "    clf, mapper2, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "clf = lgb.LGBMClassifier(random_state=42)\n",
    "print(\"Essai avec LGBMClassifier et SMOOTEEN pour le mapper 1\")\n",
    "lgb_1 = test_model_with_sampling(\n",
    "    clf, mapper1, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")\n",
    "print(\"Essai avec LGBMClassifier et SMOOTEEN pour le mapper 2\")\n",
    "lgb_2 = test_model_with_sampling(\n",
    "    clf, mapper2, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(random_state=42)\n",
    "print(\"Essai avec MLPClassifier et SMOOTEEN pour le mapper 1\")\n",
    "mlp_1 = test_model_with_sampling(\n",
    "    clf, mapper1, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")\n",
    "print(\"Essai avec MLPClassifier et SMOOTEEN pour le mapper 2\")\n",
    "mlp_2 = test_model_with_sampling(\n",
    "    clf, mapper2, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=42)\n",
    "print(\"Essai avec AdaBoostClassifier et SMOOTEEN pour le mapper 1\")\n",
    "ada_1 = test_model_with_sampling(\n",
    "    clf, mapper1, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")\n",
    "print(\"Essai avec AdaBoostClassifier et SMOOTEEN pour le mapper 2\")\n",
    "ada_2 = test_model_with_sampling(\n",
    "    clf, mapper2, smoteen, X_train, y_train, X_test, y_test, le\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, l'estimateur AdaBoost, la regression logistique et le réseau de neurones semblent les plus performant en terme de recall, cependant, AdaBoost a un meilleur score f1 que les deux autres. Nous allons donc utiliser celui-ci, avec le mapper 1 et le sampler SMOTEEN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des hyperparamètres\n",
    "\n",
    "Maintenant, nous allons voir s'il est possible d'améliorer le modèle en optimisant les hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    estimator=AdaBoostClassifier(random_state=42),\n",
    "    param_grid={\n",
    "        \"n_estimators\": [50, 100, 200, 400],\n",
    "        \"learning_rate\": [0.1, 0.5, 1.0],\n",
    "    },\n",
    "    scoring=\"recall\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed = le.transform(y_train)\n",
    "X_train_processed = mapper1.fit_transform(X_train, y_train_processed)\n",
    "X_test_processed = mapper1.transform(X_test)\n",
    "X_res, y_res = smoteen.fit_resample(X_train_processed, y_train_processed)\n",
    "gscv.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que les meilleurs paramètres sont différents des valeurs par défaut, qui sont 50 estimateurs et 1.0 pour le paramètre `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion pour le modèle issu de la GridSearch\n",
    "print(\"Score du modèle AdaboostClassifier sélectionné avec GridSearch\")\n",
    "y_true, y_pred = le.transform(y_test), gscv.predict(X_test_processed)\n",
    "plot_results(y_true, y_pred, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle par défaut qui a été sélectionné plus haut.\n",
    "print(\"Score du modèle AdaboostClassifier précédemment sélectionné\")\n",
    "test_model_with_sampling(\n",
    "    AdaBoostClassifier(\n",
    "        **{\n",
    "            \"algorithm\": \"SAMME.R\",\n",
    "            \"base_estimator\": None,\n",
    "            \"learning_rate\": 1.0,\n",
    "            \"n_estimators\": 50,\n",
    "        }\n",
    "    ),\n",
    "    mapper1,\n",
    "    smoteen,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    le,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, quand on compare les deux matrices de confusion, on voit que le premier modèle est légerement meilleur que le second. Par contre, le modèle issu de la GridSearch a un meilleur score f1.\n",
    "Il reste à voir si la performance ajoutée avec ce modèle est suffisante pour compenser la complexité fortement accrue. En effet, le modèle de classification le plus simple fonctionnait déjà très bien, il faut voir si on peut l'optimiser un peu et s'il devient meilleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score de la regression logistique\")\n",
    "lr_smoteen = test_model_with_sampling(\n",
    "    LogisticRegression(random_state=42),\n",
    "    mapper1,\n",
    "    smoteen,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    le,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv2 = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42, n_jobs=-1),\n",
    "    param_grid={\n",
    "        \"C\": [0.1, 0.5, 1.0, 5.0],\n",
    "        \"max_iter\": [100, 200, 500],\n",
    "        \"penalty\": [\"l1\", \"l2\", \"none\"],\n",
    "        \"fit_intercept\": [True, False],\n",
    "    },\n",
    "    scoring=[\"recall\", \"f1\"],\n",
    "    refit=\"f1\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "gscv2.fit(X_res, y_res)\n",
    "gscv2.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion pour le modèle de regression logistique issu de la GridSearch\n",
    "print(\"Score de la regression logistique sélectionnée avec GridSearch\")\n",
    "plot_results(le.transform(y_test), gscv2.predict(X_test_processed), le)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au final, on vient bien que la régression linéaire est très performante bien que c'est un modèle très simple. Je vais donc choisir ce modèle car il sera plus simple à expliquer et à interpréter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicabilité du modèle sélectionné\n",
    "\n",
    "Dans cette partie, nous allons nous pencher plus en détails sur les variables qui ont un impact sur les décisions du modèle. Pour ce faire, nous allons utiliser le package `explainerdashboard` et `shap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "\n",
    "cats = [\n",
    "    {\n",
    "        \"id_forfait\": [\n",
    "            \"id_forfait_x0_Dkgo\",\n",
    "            \"id_forfait_x0_Dkji\",\n",
    "            \"id_forfait_x0_Dkop\",\n",
    "            \"id_forfait_x0_Dktt\",\n",
    "            \"id_forfait_x0_Dkwg\",\n",
    "        ]\n",
    "    },\n",
    "    {\"contrat\": [\"contrat_x0_Mensuel\", \"contrat_x0_deux ans\", \"contrat_x0_un an\"]},\n",
    "    {\n",
    "        \"methode_paiement\": [\n",
    "            \"methode_paiement_x0_Carte de credit Automatique\",\n",
    "            \"methode_paiement_x0_Cheque electronique\",\n",
    "            \"methode_paiement_x0_Cheque par mail\",\n",
    "            \"methode_paiement_x0_RIB Automatique\",\n",
    "        ]\n",
    "    },\n",
    "    {\"genre\": [\"genre_x0_Madame\", \"genre_x0_Mademoiselle\", \"genre_x0_Monsieur\"]},\n",
    "    {\"senior\": [\"senior_x0_Non\", \"senior_x0_Oui\"]},\n",
    "    {\"couple\": [\"couple_x0_Non\", \"couple_x0_Oui\"]},\n",
    "    {\n",
    "        \"option_service_telephonique\": [\n",
    "            \"option_service_telephone_x0_Non\",\n",
    "            \"option_service_telephone_x0_Oui\",\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"service_internet\": [\n",
    "            \"service_internet_x0_DSL\",\n",
    "            \"service_internet_x0_Fibre\",\n",
    "            \"service_internet_x0_Non\",\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "tmp = pd.DataFrame(\n",
    "    X_test_processed, columns=ct.get_feature_names_out(), index=y_test.index\n",
    ")\n",
    "explainer = ClassifierExplainer(\n",
    "    gscv2.best_estimator_,\n",
    "    tmp,\n",
    "    le.transform(y_test),\n",
    "    cats=cats,\n",
    "    labels=le.classes_.tolist(),\n",
    "    idxs=y_test.index,\n",
    "    index_name=\"Id Client\",\n",
    "    target=\"Résiliation\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "db = ExplainerDashboard(explainer, title=\"Resiliation Model Explainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.run(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce dashboard interactif permet les shap values et donc l'importance des différentes variables sur le modèle.\n",
    "\n",
    "Dans ce cas, on voit que les factures et l'ancienneté sont les variables les plus importantes pour décider si un client est résilier ou non. Il faut quand même noter que ces variables sont très corrélées, et donc interchangeables, car la facture totale est presque égale au produit de la facture mensuelle moyenne et de l'ancienneté.\n",
    "\n",
    "Sinon, on voit que la durée du contrat est également très importante.\n",
    "\n",
    "D'un autre côté, les variables genre, senior et couple ont un impact très faibles sur le modèle, ce qui peut être étonnant, surtout pour la situation conjuguale.\n",
    "\n",
    "Ce dashboard permet également de voir les shap values pour les clients individuellement et ainsi de comprendre comment l'algorithme prend la décision. On peut aussi, changer la valeur d'un paramètre d'un client pour voir si la décision change.\n",
    "\n",
    "Le graphique **Precision Plot** dans l'onglet **Classification Stats** montre que les décisions sont très souvent bien claires et que la majorité des clients qui résilient sont bien classés. Pour encore améliorer le score, on aurait pu baisser le threshold en dessous de 0.5.\n",
    "\n",
    "On y voit aussi les courbes de trade-off entre la précision et le recall. Et on voit très clairement que le recall est privilégié par rapport à la précision. Ce que se traduit par une assez mauvaise classification des clients ne souhaitant pas résilier. Cependant, ce n'était pas mon objectif. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shap Beeswarm\n",
    "\n",
    "Pour comprendre l'impact positif ou négatif des variables, le package `shap` fournit le graphique Beeswarm qui illustre bien cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.Explainer(gscv2.best_estimator_, tmp)\n",
    "shap_values = explainer(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values, order=shap_values.abs.max(0), max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique montre qu'une facture totale élévée a un impact négatif sur la décision du modèle, à savoir que le client va résilier. Ceci s'explique par le fait que les clients avec une facture totale élevée sont anciens et ont moins de chance de résilier.\n",
    "\n",
    "Au contraire, une facture mensuelle faible se traduit par plus de résiliation, il y a probablement plusieurs facteurs pouvant expliquer cela, on peut supposer que le fait que les clients avec un \"petit\" forfait ont plus tendance à en changer.\n",
    "\n",
    "Le type de contrat à aussi un impact, par exemple, les longs contrats (de 2 ans) sont préférables à ceux de moins de 1 mois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ainsi, on a construit un modèle de classification dont l'objectif principal est de déterminer si un client va résilier, dans l'optique d'essayer de le conserver en lui proposant des offres ou en faisant un démarchage plus ciblé. Pour cette tâche l'algorithme utilisé est performant, bien qu'il soit très simple. Il est donc facile d'expliquer les décisions avec les shap values notamment.\n",
    "\n",
    "#### Points à améliorer ou à approfondir\n",
    "\n",
    "Je vais finir par proposer des pistes d'améliorations ou de développements plus complexes.\n",
    "\n",
    "* Premièrement, il faudrait voir si on peut améliorer la précision du modèle tout en gardant le recall faible.\n",
    "* Pour ce faire, il semble pertinent de tester différentes méthodes de preprocessing des données, des méthodes d'*Imputing* plus adaptée notamment. Et de voir si on peut ajouter d'autres sources.\n",
    "* Il faut aussi tester d'autres modèles qui peuvent être plus performants.\n",
    "* Pour cela, on peut aussi améliorer l'optimisation des hyperparamètres, avec une librairie comme `optuna` à la place de GridSearch CV par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repo GitHub du projet: https://github.com/gwatkinson/test-technique-bouygues"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc21c02a279bcb22cc3b46a4a7a525cff8d19105de1c6809b0868c3909f71c5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
